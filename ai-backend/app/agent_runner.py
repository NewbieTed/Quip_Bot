from app.graph import graph


async def run_agent(member_message: str, member_id: int):
    if not isinstance(member_message, str) or not member_message.strip():
        yield "Error: Provided message must be a non-empty string."
        return

    config = {"configurable": {"thread_id": member_id}}

    messages = [
        {
            "role": "system",
            "content": (
                "You are a helpful assistant for a Discord bot service. Perform the user's request and report the results clearly. "
                "If you cannot accomplish the task, inform the user politely. Always provide a final clear response to the user summarizing what you did."
            )
        },
        {
            "role": "user",
            "content": member_message.strip()
        }
    ]

    last_content = None
    try:
        async for mode, chunk in graph.astream({"messages": messages}, config, stream_mode=["updates", "messages", "custom"]):
            print(f"[STREAM MODE] {mode}", flush=True)
            if mode == "messages":
                print(f"[MESSAGE STREAM] {chunk}", flush=True)
                if isinstance(chunk, dict) and "messages" in chunk:
                    partial_message = chunk["messages"][-1].content
                    yield partial_message
                continue
            if mode == "custom":
                if isinstance(chunk, dict):
                    message = chunk.get('progress', chunk)
                else:
                    message = chunk
                print(f"[CUSTOM STREAM] {message}", flush=True)
                yield message
                continue
            for value in chunk.values():
                if isinstance(value, dict) and "messages" in value:
                    last_content = value["messages"][-1].content
    except Exception as e:
        import traceback
        print("[STREAM ERROR]", e, flush=True)
        traceback.print_exc()
        yield f"Error: {str(e)}"

    if last_content:
        yield last_content
    else:
        yield "No response generated by the assistant."
