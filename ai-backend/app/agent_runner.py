from app.graph import graph

from pathlib import Path
SYSTEM_PROMPT_PATH = Path("app/prompts/system_prompt.txt")

def load_system_prompt() -> str:
    return SYSTEM_PROMPT_PATH.read_text(encoding="utf-8").strip()

async def run_agent(member_message: str, member_id: int, channel_id: int):
    if not isinstance(member_message, str) or not member_message.strip():
        yield "Error: Provided message must be a non-empty string."
        return

    config = {"configurable": {"thread_id": member_id}}
    system_message: str = load_system_prompt()
    system_user_data: str = f"Member ID: {member_id}, \nChannel ID: {channel_id}"
    messages = [
        {
            "role": "system",
            "content": system_message + "\n" + system_user_data
        },
        {
            "role": "user",
            "content": member_message.strip()
        }
    ]

    last_content = None
    try:
        async for mode, chunk in graph.astream({"messages": messages}, config, stream_mode=["updates", "messages", "custom"]):
            # print(f"[STREAM MODE] {mode}", flush=True)
            if mode == "messages":
                # print(f"[MESSAGE STREAM] {chunk}", flush=True)
                if isinstance(chunk, dict) and "messages" in chunk:
                    partial_message = chunk["messages"][-1].content
                    yield partial_message
                continue
            if mode == "custom":
                if isinstance(chunk, dict):
                    message = chunk.get('progress', chunk)
                else:
                    message = chunk
                print(f"[CUSTOM STREAM] {message}", flush=True)
                yield message
                continue
            for value in chunk.values():
                if isinstance(value, dict) and "messages" in value:
                    last_content = value["messages"][-1].content
    except Exception as e:
        import traceback
        print("[STREAM ERROR]", e, flush=True)
        traceback.print_exc()
        yield f"Error: {str(e)}"

    if last_content:
        yield last_content
    else:
        yield "No response generated by the assistant."
